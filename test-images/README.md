# OCI-Extract Test Images

This directory contains test images used for integration testing of OCI-Extract.

## Directory Structure

```
test-images/
├── base/              # Simple single-layer test image
│   ├── Dockerfile
│   └── testdata/      # Test files of various sizes
├── multilayer/        # Multi-layer test image
│   └── Dockerfile
└── README.md
```

## Test Images

### Base Image
- **Purpose**: Test basic extraction functionality
- **Contents**:
  - `small.txt` - Small text file (< 1KB)
  - `medium.json` - JSON configuration (~10KB)
  - `large.bin` - Binary file (1MB) - **generated dynamically by tests**
  - `nested/deep/file.txt` - Nested file for path testing
  - `build-info.txt` - Generated at build time

**Note**: `large.bin` is not committed to the repository. It's generated by the integration tests in `TestMain` before building images.

### Multi-Layer Image
- **Purpose**: Test layer traversal and file overwriting
- **Layers**: 4 distinct layers
- **Contents**: Files spread across multiple layers

## Building Test Images Locally

### Prerequisites
- Docker or Podman
- Access to GitHub Container Registry (for pushing)

### Build Commands

```bash
# Build base image
docker build -t ghcr.io/YOUR_USERNAME/oci-extract-test:standard ./base

# Build multi-layer image
docker build -t ghcr.io/YOUR_USERNAME/oci-extract-test:multilayer-standard ./multilayer

# Push to registry
docker push ghcr.io/YOUR_USERNAME/oci-extract-test:standard
docker push ghcr.io/YOUR_USERNAME/oci-extract-test:multilayer-standard
```

### Converting to eStargz

Using nerdctl (requires sudo to access Docker's containerd):
```bash
# Pull the standard image first
sudo nerdctl pull ghcr.io/YOUR_USERNAME/oci-extract-test:standard

# Convert to eStargz
sudo nerdctl image convert \
  --estargz \
  --oci \
  ghcr.io/YOUR_USERNAME/oci-extract-test:standard \
  ghcr.io/YOUR_USERNAME/oci-extract-test:estargz

# Push eStargz image
sudo nerdctl push ghcr.io/YOUR_USERNAME/oci-extract-test:estargz
```

### Converting to zstd

Using nerdctl (requires sudo to access Docker's containerd):
```bash
# Pull the standard image first
sudo nerdctl pull ghcr.io/YOUR_USERNAME/oci-extract-test:standard

# Convert to zstd
sudo nerdctl image convert \
  --zstd \
  --oci \
  ghcr.io/YOUR_USERNAME/oci-extract-test:standard \
  ghcr.io/YOUR_USERNAME/oci-extract-test:zstd

# Push zstd image
sudo nerdctl push ghcr.io/YOUR_USERNAME/oci-extract-test:zstd
```

### Converting to zstd:chunked

Using nerdctl (requires sudo to access Docker's containerd):
```bash
# Pull the standard image first
sudo nerdctl pull ghcr.io/YOUR_USERNAME/oci-extract-test:standard

# Convert to zstd:chunked
sudo nerdctl image convert \
  --zstdchunked \
  --oci \
  ghcr.io/YOUR_USERNAME/oci-extract-test:standard \
  ghcr.io/YOUR_USERNAME/oci-extract-test:zstd-chunked

# Push zstd:chunked image
sudo nerdctl push ghcr.io/YOUR_USERNAME/oci-extract-test:zstd-chunked
```

### Creating SOCI Indices

Using SOCI CLI (requires sudo to access containerd socket):
```bash
# Create SOCI index with --min-layer-size 0 for small test images
sudo soci create --min-layer-size 0 ghcr.io/YOUR_USERNAME/oci-extract-test:standard

# Push SOCI index
sudo soci push ghcr.io/YOUR_USERNAME/oci-extract-test:standard
```

**Note**: The `--min-layer-size 0` flag is required because our test images have small layers. By default, SOCI skips layers smaller than 10MB.

## Testing Locally

```bash
# Build oci-extract
cd ../..
make build

# Test extraction
./oci-extract extract ghcr.io/YOUR_USERNAME/oci-extract-test:standard \
  /testdata/small.txt \
  -o /tmp/small.txt \
  --verbose

# Verify content
cat /tmp/small.txt
```

## Automated Testing

These images are automatically built and pushed by the integration tests themselves, which run in the GitHub Actions CI workflow (`.github/workflows/ci.yml`).

The integration tests (written in Go) automatically:
1. Generate test data (`large.bin`)
2. Build standard Docker images using these Dockerfiles
3. Convert to eStargz format (if nerdctl available)
4. Create SOCI indices (if soci available)
5. Convert to zstd format (if nerdctl available)
6. Convert to zstd:chunked format (if nerdctl available)
7. Push all variants to GHCR
8. Run extraction tests against all formats

This approach keeps the image building logic in the test code, making it easier to maintain and modify.

## Image Tags

Each test image is tagged with:
- `standard` - Latest standard OCI image
- `estargz` - Latest eStargz-converted image
- `soci` - Latest SOCI-indexed image (same as standard, but with index)
- `zstd` - Latest zstd-compressed image
- `zstd-chunked` - Latest zstd:chunked-converted image
- `multilayer-standard` - Multi-layer standard image
- `multilayer-estargz` - Multi-layer eStargz image
- `multilayer-soci` - Multi-layer SOCI-indexed image
- `multilayer-zstd` - Multi-layer zstd-compressed image
- `multilayer-zstd-chunked` - Multi-layer zstd:chunked image
- `{format}-{git-sha}` - Specific commit version

## Maintenance

### Image Rebuilds

Test images are rebuilt on every CI run:
- Tagged with both `latest` and the Git commit SHA
- SHA-tagged images enable testing specific versions
- Rebuilds ensure images stay in sync with test code

### Base Image Updates

To update the base Alpine version:
1. Update `FROM alpine:3.19` in Dockerfiles to newer version
2. Commit and push changes
3. CI will automatically rebuild with new base

### Cleanup

Old SHA-tagged images accumulate over time. To clean up manually:
```bash
# List all test images
docker images | grep oci-extract-test

# Remove old SHA-tagged images (keep latest + last 10)
docker image prune -af --filter "label=test.purpose=integration-testing"
```

**Note**: There's currently no automated cleanup policy. Consider implementing GHCR package retention policies if storage becomes an issue.
